<!DOCTYPE html>
<html>
<head>
  <meta name="databricks-html-version" content="1">
<title>SparkML_Demo_Text and Turning - Databricks</title>

<meta charset="utf-8">
<meta name="google" content="notranslate">
<meta http-equiv="Content-Language" content="en">
<meta http-equiv="Content-Type" content="text/html; charset=UTF8">
<link rel="stylesheet"
  href="https://fonts.googleapis.com/css?family=Source+Code+Pro:400,700">

<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/lib/css/bootstrap.min.css">
<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/lib/jquery-ui-bundle/jquery-ui.min.css">
<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/css/main.css">
<link rel="stylesheet" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/css/print.css" media="print">
<link rel="icon" type="image/png" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/img/favicon.ico"/>
<script>window.settings = {"enableSshKeyUI":true,"enableAutoCompleteAsYouType":[],"devTierName":"Community Edition","workspaceFeaturedLinks":[{"linkURI":"https://docs.databricks.com/index.html","displayName":"Documentation","icon":"question"},{"linkURI":"https://docs.databricks.com/release-notes/product/latest.html","displayName":"Release Notes","icon":"code"},{"linkURI":"https://docs.databricks.com/spark/latest/training/index.html","displayName":"Training & Tutorials","icon":"graduation-cap"}],"enableClearStateFeature":false,"dbcForumURL":"http://forums.databricks.com/","maxCustomTags":45,"enableInstanceProfilesUIInJobs":true,"nodeInfo":{"node_types":[{"spark_heap_memory":4800,"instance_type_id":"r3.2xlarge","spark_core_oversubscription_factor":8.0,"node_type_id":"dev-tier-node","description":"Community Optimized","support_cluster_tags":false,"container_memory_mb":6000,"memory_mb":6144,"category":"Community Edition","num_cores":0.88,"support_ebs_volumes":false}],"default_node_type_id":"dev-tier-node"},"enableThirdPartyApplicationsUI":false,"enableClusterAcls":true,"notebookRevisionVisibilityHorizon":999999,"enableTableHandler":true,"maxEbsVolumesPerInstance":10,"isAdmin":true,"deltaProcessingBatchSize":1000,"enableLargeResultDownload":true,"zoneInfos":[{"id":"us-west-2c","isDefault":true},{"id":"us-west-2b","isDefault":false},{"id":"us-west-2a","isDefault":false}],"enableEBSVolumesUIForJobs":true,"enablePublishNotebooks":true,"enableMaxConcurrentRuns":true,"enableJobAclsConfig":false,"enableFullTextSearch":false,"enableElasticSparkUI":false,"enableNewClustersCreate":false,"clusters":true,"allowRunOnPendingClusters":true,"applications":false,"fileStoreBase":"FileStore","enableSshKeyUIInJobs":true,"enableDetachAndAttachSubMenu":false,"configurableSparkOptionsSpec":[{"keyPattern":"spark\\.kryo(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.kryo.*","valuePatternDisplay":"*","description":"Configuration options for Kryo serialization"},{"keyPattern":"spark\\.io\\.compression\\.codec","valuePattern":"(lzf|snappy|org\\.apache\\.spark\\.io\\.LZFCompressionCodec|org\\.apache\\.spark\\.io\\.SnappyCompressionCodec)","keyPatternDisplay":"spark.io.compression.codec","valuePatternDisplay":"snappy|lzf","description":"The codec used to compress internal data such as RDD partitions, broadcast variables and shuffle outputs."},{"keyPattern":"spark\\.serializer","valuePattern":"(org\\.apache\\.spark\\.serializer\\.JavaSerializer|org\\.apache\\.spark\\.serializer\\.KryoSerializer)","keyPatternDisplay":"spark.serializer","valuePatternDisplay":"org.apache.spark.serializer.JavaSerializer|org.apache.spark.serializer.KryoSerializer","description":"Class to use for serializing objects that will be sent over the network or need to be cached in serialized form."},{"keyPattern":"spark\\.rdd\\.compress","valuePattern":"(true|false)","keyPatternDisplay":"spark.rdd.compress","valuePatternDisplay":"true|false","description":"Whether to compress serialized RDD partitions (e.g. for StorageLevel.MEMORY_ONLY_SER). Can save substantial space at the cost of some extra CPU time."},{"keyPattern":"spark\\.speculation","valuePattern":"(true|false)","keyPatternDisplay":"spark.speculation","valuePatternDisplay":"true|false","description":"Whether to use speculation (recommended off for streaming)"},{"keyPattern":"spark\\.es(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"es(\\.([^\\.]+))+","valuePattern":".*","keyPatternDisplay":"es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"spark\\.(storage|shuffle)\\.memoryFraction","valuePattern":"0?\\.0*([1-9])([0-9])*","keyPatternDisplay":"spark.(storage|shuffle).memoryFraction","valuePatternDisplay":"(0.0,1.0)","description":"Fraction of Java heap to use for Spark's shuffle or storage"},{"keyPattern":"spark\\.streaming\\.backpressure\\.enabled","valuePattern":"(true|false)","keyPatternDisplay":"spark.streaming.backpressure.enabled","valuePatternDisplay":"true|false","description":"Enables or disables Spark Streaming's internal backpressure mechanism (since 1.5). This enables the Spark Streaming to control the receiving rate based on the current batch scheduling delays and processing times so that the system receives only as fast as the system can process. Internally, this dynamically sets the maximum receiving rate of receivers. This rate is upper bounded by the values `spark.streaming.receiver.maxRate` and `spark.streaming.kafka.maxRatePerPartition` if they are set."},{"keyPattern":"spark\\.streaming\\.receiver\\.maxRate","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.receiver.maxRate","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which each receiver will receive data. Effectively, each stream will consume at most this number of records per second. Setting this configuration to 0 or a negative number will put no limit on the rate. See the deployment guide in the Spark Streaming programing guide for mode details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRatePerPartition","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRatePerPartition","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which data will be read from each Kafka partition when using the Kafka direct stream API introduced in Spark 1.3. See the Kafka Integration guide for more details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRetries","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRetries","valuePatternDisplay":"numeric","description":"Maximum number of consecutive retries the driver will make in order to find the latest offsets on the leader of each partition (a default value of 1 means that the driver will make a maximum of 2 attempts). Only applies to the Kafka direct stream API introduced in Spark 1.3."},{"keyPattern":"spark\\.streaming\\.ui\\.retainedBatches","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.ui.retainedBatches","valuePatternDisplay":"numeric","description":"How many batches the Spark Streaming UI and status APIs remember before garbage collecting."}],"enableReactNotebookComments":true,"enableAdminPasswordReset":false,"enableResetPassword":true,"maxClusterTagValueLength":255,"enableJobsSparkUpgrade":true,"sparkVersions":[{"key":"1.6.x-ubuntu15.10","displayName":"Spark 1.6.x (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"1.4.x-ubuntu15.10","displayName":"Spark 1.4.1 (Hadoop 1)","packageLabel":"spark-image-f710650fb8aaade8e4e812368ea87c45cd8cd0b5e6894ca6c94f3354e8daa6dc","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.0-ubuntu15.10-scala2.10","displayName":"Spark 2.0.0 (Scala 2.10)","packageLabel":"spark-image-073c1b52ace74f251fae2680624a0d8d184a8b57096d1c21c5ce56c29be6a37a","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.x-ubuntu15.10-hadoop1","displayName":"Spark 1.6.x (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"1.6.1-ubuntu15.10-hadoop1","displayName":"Spark 1.6.1 (Hadoop 1)","packageLabel":"spark-image-21d1cac181b7b8856dd1b4214a3a734f95b5289089349db9d9c926cb87d843db","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.2-ubuntu15.10-hadoop1","displayName":"Spark 1.6.2 (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.3-db1-hadoop2-scala2.10","displayName":"Spark 1.6.3-db1 (Hadoop 2, Scala 2.10)","packageLabel":"spark-image-eaa8d9b990015a14e032fb2e2e15be0b8d5af9627cd01d855df728b67969d5d9","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.2-ubuntu15.10-hadoop2","displayName":"Spark 1.6.2 (Hadoop 2)","packageLabel":"spark-image-161245e66d887cd775e23286a54bab0b146143e1289f25bd1732beac454a1561","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.1-ubuntu15.10-hadoop2","displayName":"Spark 1.6.1 (Hadoop 2)","packageLabel":"spark-image-4cafdf8bc6cba8edad12f441e3b3f0a8ea27da35c896bc8290e16b41fd15496a","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.2-db2-scala2.10","displayName":"Spark 2.0.2-db2 (Scala 2.10)","packageLabel":"spark-image-36d48f22cca7a907538e07df71847dd22aaf84a852c2eeea2dcefe24c681602f","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.x-ubuntu15.10-scala2.11","displayName":"Spark 2.0 (Ubuntu 15.10, Scala 2.11, deprecated)","packageLabel":"spark-image-8e1c50d626a52eac5a6c8129e09ae206ba9890f4523775f77af4ad6d99a64c44","upgradable":true,"deprecated":true,"customerVisible":true},{"key":"2.0.x-scala2.10","displayName":"Spark 2.0 (Auto-updating, Scala 2.10)","packageLabel":"spark-image-4f22a8d3016bc3dce9e839b10418815a7d28afff3a027b43bd2b041c42b2a89d","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.2-db1-scala2.11","displayName":"Spark 2.0.2-db1 (Scala 2.11)","packageLabel":"spark-image-c2d623f03dd44097493c01aa54a941fc31978ebe6d759b36c75b716b2ff6ab9c","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.5.x-ubuntu15.10","displayName":"Spark 1.5.2 (Hadoop 1)","packageLabel":"spark-image-c9d2a8abf41f157a4acc6d52bc721090346f6fea2de356f3a66e388f54481698","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.x-scala2.11","displayName":"Spark 2.0 (Auto-updating, Scala 2.11)","packageLabel":"spark-image-596490ba3e0ca4b62abb048923fc70de84e319cf527bb7a5a8f609bbf780bed8","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.2-db2-scala2.11","displayName":"Spark 2.0.2-db2 (Scala 2.11)","packageLabel":"spark-image-4fa852ba378e97815083b96c9cada7b962a513ec23554a5fc849f7f1dd8c065a","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.3.x-ubuntu15.10","displayName":"Spark 1.3.0 (Hadoop 1)","packageLabel":"spark-image-40d2842670bc3dc178b14042501847d76171437ccf70613fa397a7a24c48b912","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.1-db1-scala2.11","displayName":"Spark 2.0.1-db1 (Scala 2.11)","packageLabel":"spark-image-10ab19f634bbfdb860446c326a9f76dc25bfa87de6403b980566279142a289ea","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.3-db1-hadoop1-scala2.10","displayName":"Spark 1.6.3-db1 (Hadoop 1, Scala 2.10)","packageLabel":"spark-image-d50af1032799546b8ccbeeb76889a20c819ebc2a0e68ea20920cb30d3895d3ae","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.2-db1-scala2.10","displayName":"Spark 2.0.2-db1 (Scala 2.10)","packageLabel":"spark-image-654bdd6e9bad70079491987d853b4b7abf3b736fff099701501acaabe0e75c41","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.x-ubuntu15.10","displayName":"Spark 2.0 (Ubuntu 15.10, Scala 2.10, deprecated)","packageLabel":"spark-image-a659f3909d51b38d297b20532fc807ecf708cfb7440ce9b090c406ab0c1e4b7e","upgradable":true,"deprecated":true,"customerVisible":true},{"key":"2.0.1-db1-scala2.10","displayName":"Spark 2.0.1-db1 (Scala 2.10)","packageLabel":"spark-image-5a13c2db3091986a4e7363006cc185c5b1108c7761ef5d0218506cf2e6643840","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.0-ubuntu15.10","displayName":"Spark 1.6.0 (Hadoop 1)","packageLabel":"spark-image-10ef758029b8c7e19cd7f4fb52fff9180d75db92ca071bd94c47f3c1171a7cb5","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.x-ubuntu15.10-hadoop2","displayName":"Spark 1.6.x (Hadoop 2)","packageLabel":"spark-image-161245e66d887cd775e23286a54bab0b146143e1289f25bd1732beac454a1561","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"2.0.0-ubuntu15.10-scala2.11","displayName":"Spark 2.0.0 (Scala 2.11)","packageLabel":"spark-image-b4ec141e751f201399f8358a82efee202560f7ed05e1a04a2ae8778f6324b909","upgradable":true,"deprecated":false,"customerVisible":true}],"enableRestrictedClusterCreation":true,"enableFeedback":true,"enableClusterAutoScaling":false,"enableUserVisibleDefaultTags":false,"defaultNumWorkers":0,"serverContinuationTimeoutMillis":10000,"driverStderrFilePrefix":"stderr","enableNotebookRefresh":false,"accountsOwnerUrl":"https://accounts.cloud.databricks.com/registration.html#login","driverStdoutFilePrefix":"stdout","defaultNodeTypeToPricingUnitsMap":{"r3.2xlarge":2,"class-node":1,"p2.8xlarge":16,"r3.8xlarge":8,"dev-tier-node":1,"c3.8xlarge":4,"r3.4xlarge":4,"i2.4xlarge":6,"development-node":1,"i2.2xlarge":3,"g2.8xlarge":6,"memory-optimized":1,"p2.16xlarge":24,"c3.2xlarge":1,"c4.2xlarge":1,"i2.xlarge":1.5,"compute-optimized":1,"c4.4xlarge":2,"c3.4xlarge":2,"g2.2xlarge":1.5,"p2.xlarge":2,"c4.8xlarge":4,"r3.xlarge":1,"i2.8xlarge":12},"enableSparkDocsSearch":true,"sparkHistoryServerEnabled":true,"enableEBSVolumesUI":false,"sanitizeMarkdownHtml":true,"enableIPythonImportExport":true,"enableClusterTagsUIForJobs":false,"enableClusterTagsUI":false,"enableNotebookHistoryDiffing":true,"branch":"2.34","accountsLimit":3,"enableX509Authentication":false,"enableNotebookGitBranching":true,"local":false,"enableClusterAutoScalingForJobs":false,"enableStrongPassword":false,"displayDefaultContainerMemoryGB":6,"disableS3TableImport":false,"deploymentMode":"production","useSpotForWorkers":true,"enableUserInviteWorkflow":true,"enableStaticNotebooks":true,"enableCssTransitions":true,"minClusterTagKeyLength":1,"showHomepageFeaturedLinks":true,"pricingURL":"https://databricks.com/product/pricing","enableClusterAclsConfig":false,"useTempS3UrlForTableUpload":false,"notifyLastLogin":false,"enableNotebookGitVersioning":true,"files":"files/","feedbackEmail":"feedback@databricks.com","enableDriverLogsUI":true,"disableLegacyDashboards":true,"enableWorkspaceAclsConfig":false,"dropzoneMaxFileSize":4096,"enableNewClustersList":false,"enableNewDashboardViews":true,"driverLog4jFilePrefix":"log4j","enableSingleSignOn":true,"enableMavenLibraries":true,"displayRowLimit":1000,"deltaProcessingAsyncEnabled":true,"defaultSparkVersion":{"key":"2.0.x-scala2.10","displayName":"Spark 2.0 (Auto-updating, Scala 2.10)","packageLabel":"spark-image-4f22a8d3016bc3dce9e839b10418815a7d28afff3a027b43bd2b041c42b2a89d","upgradable":true,"deprecated":false,"customerVisible":true},"enableCustomSpotPricing":true,"enableMountAclsConfig":false,"useDevTierHomePage":true,"enablePublishHub":false,"notebookHubUrl":"http://hub.dev.databricks.com/","showSqlEndpoints":false,"enableClusterAclsByTier":false,"databricksDocsBaseUrl":"https://docs.databricks.com/","disallowAddingAdmins":true,"enableSparkConfUI":true,"featureTier":"DEVELOPER_BASIC_TIER","enableOrgSwitcherUI":true,"clustersLimit":1,"enableJdbcImport":true,"logfiles":"logfiles/","enableWebappSharding":true,"enableClusterDeltaUpdates":true,"enableSingleSignOnLogin":false,"ebsVolumeSizeLimitGB":{"GENERAL_PURPOSE_SSD":[100,4096],"THROUGHPUT_OPTIMIZED_HDD":[500,4096]},"enableMountAcls":false,"requireEmailUserName":true,"enableDashboardViews":false,"dbcFeedbackURL":"mailto:feedback@databricks.com","enableMountAclService":true,"enableWorkspaceAcls":false,"maxClusterTagKeyLength":127,"gitHash":"bcda81cf895a136c83055406bb2c4fd701411084-dirty","showWorkspaceFeaturedLinks":true,"signupUrl":"https://databricks.com/try-databricks","allowFeedbackForumAccess":true,"enableImportFromUrl":true,"enableMiniClusters":true,"enableDebugUI":false,"allowNonAdminUsers":true,"enableSingleSignOnByTier":false,"enableJobsRetryOnTimeout":true,"staticNotebookResourceUrl":"https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/","enableSparkPackages":true,"dynamicSparkVersions":true,"enableNotebookHistoryUI":true,"showDebugCounters":false,"enableInstanceProfilesUI":true,"enableFolderHtmlExport":true,"enableSparkVersionsUI":true,"homepageFeaturedLinks":[{"linkURI":"https://docs.databricks.com/_static/notebooks/gentle-introduction-to-apache-spark.html","displayName":"Introduction to Apache Spark on Databricks","icon":"img/home/Python_icon.svg"},{"linkURI":"https://docs.databricks.com/_static/notebooks/databricks-for-data-scientists.html","displayName":"Databricks for Data Scientists","icon":"img/home/Scala_icon.svg"},{"linkURI":"https://docs.databricks.com/_static/notebooks/structured-streaming-python.html","displayName":"Introduction to Structured Streaming","icon":"img/home/Python_icon.svg"}],"upgradeURL":"https://accounts.cloud.databricks.com/registration.html#login","notebookLoadingBackground":"#fff","sshContainerForwardedPort":2200,"enableServerAutoComplete":true,"enableStaticHtmlImport":true,"enableInstanceProfilesByTier":false,"enableTerminal":false,"defaultMemoryPerContainerMB":6000,"enablePresenceUI":true,"accounts":true,"useFramedStaticNotebooks":false,"enableNewProgressReportUI":true,"defaultCoresPerContainer":4,"enableNewClustersGet":false,"showSqlProxyUI":true};</script>
<script>var __DATABRICKS_NOTEBOOK_MODEL = {"version":"NotebookV1","origId":3726898490996302,"name":"SparkML_Demo_Text and Turning","language":"python","commands":[{"version":"CommandV1","origId":3726898490996304,"guid":"c0a45c1a-b4df-4f1b-8a35-69695a03cb0f","subtype":"command","commandType":"auto","position":1.0,"command":"# download the original dataset from http://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences\n# data already uploaded into Table at place /FileStore/tables/bsrzfmzy1481442932482/amazon_cells_labelled.txt\n\nfrom pyspark.sql import SQLContext, Row\n# Load the tab-delimited data (text files) and convert it into rowRDD, ensure to name the target variable as 'label'\nparts = sc.textFile(\"/FileStore/tables/bsrzfmzy1481442932482/amazon_cells_labelled.txt\")\nparts = parts.map(lambda l: l.split(\"\\t\"))\nrowRDD = parts.map(lambda p: Row(review=p[0],\nlabel=p[1]))\n\n# Convert the rowRDD into Spark DataFrame, and register the DataFrame as a table.\namazon = sqlContext.createDataFrame(rowRDD)\namazon.registerTempTable(\"amazon\")\n\n# Convert data type of label into integar \namazon = amazon.selectExpr(\"cast(label as int) as label\", \"review\")\n\n# Display the loaded data and its schema \namazon.show()\namazon.printSchema()\n\n#Another way to read the data: \n#amazon = sqlContext.read.format(\"csv\").option(\"inferSchema\", \"true\").option(\"delimiter\", '\\t').load(\"/FileStore/tables/bsrzfmzy1481442932482/amazon_cells_labelled.txt\")\n#amazon = amazon.selectExpr(\"_c0 as review\", \"cast(_c1 as int) as label\")\n\n","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">+-----+--------------------+\n|label|              review|\n+-----+--------------------+\n|    0|So there is no wa...|\n|    1|Good case, Excell...|\n|    1|Great for the jaw...|\n|    0|Tied to charger f...|\n|    1|   The mic is great.|\n|    0|I have to jiggle ...|\n|    0|If you have sever...|\n|    1|If you are Razr o...|\n|    0|Needless to say, ...|\n|    0|What a waste of m...|\n|    1|And the sound qua...|\n|    1|He was very impre...|\n|    0|If the two were s...|\n|    1|Very good quality...|\n|    0|The design is ver...|\n|    1|Highly recommend ...|\n|    0|I advise EVERYONE...|\n|    1|    So Far So Good!.|\n|    1|       Works great!.|\n|    0|It clicks into pl...|\n+-----+--------------------+\nonly showing top 20 rows\n\nroot\n |-- label: integer (nullable = true)\n |-- review: string (nullable = true)\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"<span class=\"ansired\">TypeError</span>: &apos;DataFrame&apos; object is not callable","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">TypeError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-35-63021c79cd4d&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">     14</span> <span class=\"ansired\"># Convert data type of label into integar</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     15</span> <span class=\"ansigreen\">from</span> pyspark<span class=\"ansiyellow\">.</span>sql<span class=\"ansiyellow\">.</span>types <span class=\"ansigreen\">import</span> IntegralType<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 16</span><span class=\"ansiyellow\"> </span>amazon<span class=\"ansiyellow\">.</span>select<span class=\"ansiyellow\">(</span>amazon<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;label&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>cast<span class=\"ansiyellow\">(</span>IntegerType<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     17</span> <span class=\"ansired\">#amazon = amazon.withColumn(&quot;labelTmp&quot;, amazon.label.cast(IntegerType))</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     18</span> <span class=\"ansired\">#amazon = amazon.withColumn(&quot;labelTmp&quot;, amazon.label.cast(IntegerType)).drop(&quot;label&quot;).withColumnRenamed(&quot;labelTmp&quot;, &quot;label&quot;)</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">TypeError</span>: &apos;DataFrame&apos; object is not callable\n</div>","workflows":[],"startTime":1.481481538034E12,"submitTime":1.481481538017E12,"finishTime":1.48148153935E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"Load Data into DataFrame","showCommandTitle":true,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"c6a6c94c-4a86-4af9-8d9b-881e2b7c75ec"},{"version":"CommandV1","origId":2850326087200626,"guid":"e516c121-caed-407a-87c7-6f0af707e21b","subtype":"command","commandType":"auto","position":2.0,"command":"from pyspark.ml.feature import Tokenizer\nfrom pyspark.ml.feature import StopWordsRemover\nfrom pyspark.ml.feature import HashingTF, IDF\nfrom pyspark.ml import Pipeline\n\n# Tokenize the review. \ntokenizer = Tokenizer(inputCol=\"review\", outputCol=\"review_words\")\nwordsDF = tokenizer.transform(amazon)\nwordsDF.show()\n\n# Remove stop words\nremover = StopWordsRemover(inputCol=\"review_words\", outputCol=\"filtered\")\nwordsDF2 = remover.transform(wordsDF)\nwordsDF2.show()\n\n# Convert to TF words vector\nhashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"TF\")\nwordsDF3 = hashingTF.transform(wordsDF2)\nwordsDF3.show()\n## HashingTF in SparkML cannot normalize term frequency with the total number of words in each document\nfor features_label in wordsDF3.select(\"TF\", \"label\").take(3):\n    print(features_label)\n\n# Convert to IDF words vector, ensure to name the features as 'features'\nidf = IDF(inputCol=\"TF\", outputCol=\"features\")\nidfModel = idf.fit(wordsDF3)\nwordsDF4 = idfModel.transform(wordsDF3)\nwordsDF4.show()\n\nfor features_label in wordsDF4.select(\"features\", \"label\").take(3):\n    print(features_label)   \n\n# Alternatively, you can use a pipeline to chain all estimators or transformers (showed in the next chunk)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">+-----+--------------------+--------------------+\n|label|              review|        review_words|\n+-----+--------------------+--------------------+\n|    0|So there is no wa...|[so, there, is, n...|\n|    1|Good case, Excell...|[good, case,, exc...|\n|    1|Great for the jaw...|[great, for, the,...|\n|    0|Tied to charger f...|[tied, to, charge...|\n|    1|   The mic is great.|[the, mic, is, gr...|\n|    0|I have to jiggle ...|[i, have, to, jig...|\n|    0|If you have sever...|[if, you, have, s...|\n|    1|If you are Razr o...|[if, you, are, ra...|\n|    0|Needless to say, ...|[needless, to, sa...|\n|    0|What a waste of m...|[what, a, waste, ...|\n|    1|And the sound qua...|[and, the, sound,...|\n|    1|He was very impre...|[he, was, very, i...|\n|    0|If the two were s...|[if, the, two, we...|\n|    1|Very good quality...|[very, good, qual...|\n|    0|The design is ver...|[the, design, is,...|\n|    1|Highly recommend ...|[highly, recommen...|\n|    0|I advise EVERYONE...|[i, advise, every...|\n|    1|    So Far So Good!.|[so, far, so, goo...|\n|    1|       Works great!.|    [works, great!.]|\n|    0|It clicks into pl...|[it, clicks, into...|\n+-----+--------------------+--------------------+\nonly showing top 20 rows\n\n+-----+--------------------+--------------------+--------------------+\n|label|              review|        review_words|            filtered|\n+-----+--------------------+--------------------+--------------------+\n|    0|So there is no wa...|[so, there, is, n...|[way, plug, us, u...|\n|    1|Good case, Excell...|[good, case,, exc...|[good, case,, exc...|\n|    1|Great for the jaw...|[great, for, the,...|   [great, jawbone.]|\n|    0|Tied to charger f...|[tied, to, charge...|[tied, charger, c...|\n|    1|   The mic is great.|[the, mic, is, gr...|       [mic, great.]|\n|    0|I have to jiggle ...|[i, have, to, jig...|[jiggle, plug, ge...|\n|    0|If you have sever...|[if, you, have, s...|[several, dozen, ...|\n|    1|If you are Razr o...|[if, you, are, ra...|[razr, owner...yo...|\n|    0|Needless to say, ...|[needless, to, sa...|[needless, say,, ...|\n|    0|What a waste of m...|[what, a, waste, ...|[waste, money, ti...|\n|    1|And the sound qua...|[and, the, sound,...|[sound, quality, ...|\n|    1|He was very impre...|[he, was, very, i...|[impressed, going...|\n|    0|If the two were s...|[if, the, two, we...|[two, seperated, ...|\n|    1|Very good quality...|[very, good, qual...|[good, quality, t...|\n|    0|The design is ver...|[the, design, is,...|[design, odd,, ea...|\n|    1|Highly recommend ...|[highly, recommen...|[highly, recommen...|\n|    0|I advise EVERYONE...|[i, advise, every...|[advise, everyone...|\n|    1|    So Far So Good!.|[so, far, so, goo...|       [far, good!.]|\n|    1|       Works great!.|    [works, great!.]|    [works, great!.]|\n|    0|It clicks into pl...|[it, clicks, into...|[clicks, place, w...|\n+-----+--------------------+--------------------+--------------------+\nonly showing top 20 rows\n\n+-----+--------------------+--------------------+--------------------+--------------------+\n|label|              review|        review_words|            filtered|                  TF|\n+-----+--------------------+--------------------+--------------------+--------------------+\n|    0|So there is no wa...|[so, there, is, n...|[way, plug, us, u...|(262144,[21872,61...|\n|    1|Good case, Excell...|[good, case,, exc...|[good, case,, exc...|(262144,[113432,1...|\n|    1|Great for the jaw...|[great, for, the,...|   [great, jawbone.]|(262144,[138356,2...|\n|    0|Tied to charger f...|[tied, to, charge...|[tied, charger, c...|(262144,[22836,35...|\n|    1|   The mic is great.|[the, mic, is, gr...|       [mic, great.]|(262144,[52197,80...|\n|    0|I have to jiggle ...|[i, have, to, jig...|[jiggle, plug, ge...|(262144,[99895,11...|\n|    0|If you have sever...|[if, you, have, s...|[several, dozen, ...|(262144,[8443,829...|\n|    1|If you are Razr o...|[if, you, are, ra...|[razr, owner...yo...|(262144,[80023,17...|\n|    0|Needless to say, ...|[needless, to, sa...|[needless, say,, ...|(262144,[15514,16...|\n|    0|What a waste of m...|[what, a, waste, ...|[waste, money, ti...|(262144,[154554,2...|\n|    1|And the sound qua...|[and, the, sound,...|[sound, quality, ...|(262144,[13381,52...|\n|    1|He was very impre...|[he, was, very, i...|[impressed, going...|(262144,[65435,93...|\n|    0|If the two were s...|[if, the, two, we...|[two, seperated, ...|(262144,[12304,13...|\n|    1|Very good quality...|[very, good, qual...|[good, quality, t...|(262144,[113432,1...|\n|    0|The design is ver...|[the, design, is,...|[design, odd,, ea...|(262144,[8287,989...|\n|    1|Highly recommend ...|[highly, recommen...|[highly, recommen...|(262144,[27545,31...|\n|    0|I advise EVERYONE...|[i, advise, every...|[advise, everyone...|(262144,[33799,37...|\n|    1|    So Far So Good!.|[so, far, so, goo...|       [far, good!.]|(262144,[28282,18...|\n|    1|       Works great!.|    [works, great!.]|    [works, great!.]|(262144,[12888,86...|\n|    0|It clicks into pl...|[it, clicks, into...|[clicks, place, w...|(262144,[27956,58...|\n+-----+--------------------+--------------------+--------------------+--------------------+\nonly showing top 20 rows\n\nRow(TF=SparseVector(262144, {21872: 1.0, 61625: 1.0, 66531: 1.0, 113100: 1.0, 172477: 1.0, 199255: 1.0}), label=0)\nRow(TF=SparseVector(262144, {113432: 1.0, 117481: 1.0, 131724: 1.0, 153328: 1.0}), label=1)\nRow(TF=SparseVector(262144, {138356: 1.0, 230310: 1.0}), label=1)\n+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n|label|              review|        review_words|            filtered|                  TF|            features|\n+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n|    0|So there is no wa...|[so, there, is, n...|[way, plug, us, u...|(262144,[21872,61...|(262144,[21872,61...|\n|    1|Good case, Excell...|[good, case,, exc...|[good, case,, exc...|(262144,[113432,1...|(262144,[113432,1...|\n|    1|Great for the jaw...|[great, for, the,...|   [great, jawbone.]|(262144,[138356,2...|(262144,[138356,2...|\n|    0|Tied to charger f...|[tied, to, charge...|[tied, charger, c...|(262144,[22836,35...|(262144,[22836,35...|\n|    1|   The mic is great.|[the, mic, is, gr...|       [mic, great.]|(262144,[52197,80...|(262144,[52197,80...|\n|    0|I have to jiggle ...|[i, have, to, jig...|[jiggle, plug, ge...|(262144,[99895,11...|(262144,[99895,11...|\n|    0|If you have sever...|[if, you, have, s...|[several, dozen, ...|(262144,[8443,829...|(262144,[8443,829...|\n|    1|If you are Razr o...|[if, you, are, ra...|[razr, owner...yo...|(262144,[80023,17...|(262144,[80023,17...|\n|    0|Needless to say, ...|[needless, to, sa...|[needless, say,, ...|(262144,[15514,16...|(262144,[15514,16...|\n|    0|What a waste of m...|[what, a, waste, ...|[waste, money, ti...|(262144,[154554,2...|(262144,[154554,2...|\n|    1|And the sound qua...|[and, the, sound,...|[sound, quality, ...|(262144,[13381,52...|(262144,[13381,52...|\n|    1|He was very impre...|[he, was, very, i...|[impressed, going...|(262144,[65435,93...|(262144,[65435,93...|\n|    0|If the two were s...|[if, the, two, we...|[two, seperated, ...|(262144,[12304,13...|(262144,[12304,13...|\n|    1|Very good quality...|[very, good, qual...|[good, quality, t...|(262144,[113432,1...|(262144,[113432,1...|\n|    0|The design is ver...|[the, design, is,...|[design, odd,, ea...|(262144,[8287,989...|(262144,[8287,989...|\n|    1|Highly recommend ...|[highly, recommen...|[highly, recommen...|(262144,[27545,31...|(262144,[27545,31...|\n|    0|I advise EVERYONE...|[i, advise, every...|[advise, everyone...|(262144,[33799,37...|(262144,[33799,37...|\n|    1|    So Far So Good!.|[so, far, so, goo...|       [far, good!.]|(262144,[28282,18...|(262144,[28282,18...|\n|    1|       Works great!.|    [works, great!.]|    [works, great!.]|(262144,[12888,86...|(262144,[12888,86...|\n|    0|It clicks into pl...|[it, clicks, into...|[clicks, place, w...|(262144,[27956,58...|(262144,[27956,58...|\n+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\nonly showing top 20 rows\n\nRow(features=SparseVector(262144, {21872: 6.2156, 61625: 6.2156, 66531: 6.2156, 113100: 4.4238, 172477: 4.9628, 199255: 4.8293}), label=0)\nRow(features=SparseVector(262144, {113432: 2.7499, 117481: 3.8177, 131724: 5.2993, 153328: 5.2993}), label=1)\nRow(features=SparseVector(262144, {138356: 2.7656, 230310: 6.2156}), label=1)\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"<span class=\"ansired\">AnalysisException</span>: u&quot;cannot resolve &apos;&#96;score&#96;&apos; given input columns: [review, review_words, label, TF, filtered];;\\n&apos;Project [TF#6765, &apos;score]\\n+- Project [label#6633, review#6634, review_words#6739, filtered#6749, UDF(filtered#6749) AS TF#6765]\\n   +- Project [label#6633, review#6634, review_words#6739, UDF(review_words#6739) AS filtered#6749]\\n      +- Project [label#6633, review#6634, UDF(review#6634) AS review_words#6739]\\n         +- LogicalRDD [label#6633, review#6634]\\n&quot;","error":"<div class=\"ansiout\">+-----+--------------------+--------------------+\n|label|              review|        review_words|\n+-----+--------------------+--------------------+\n|    0|So there is no wa...|[so, there, is, n...|\n|    1|Good case, Excell...|[good, case,, exc...|\n|    1|Great for the jaw...|[great, for, the,...|\n|    0|Tied to charger f...|[tied, to, charge...|\n|    1|   The mic is great.|[the, mic, is, gr...|\n|    0|I have to jiggle ...|[i, have, to, jig...|\n|    0|If you have sever...|[if, you, have, s...|\n|    1|If you are Razr o...|[if, you, are, ra...|\n|    0|Needless to say, ...|[needless, to, sa...|\n|    0|What a waste of m...|[what, a, waste, ...|\n|    1|And the sound qua...|[and, the, sound,...|\n|    1|He was very impre...|[he, was, very, i...|\n|    0|If the two were s...|[if, the, two, we...|\n|    1|Very good quality...|[very, good, qual...|\n|    0|The design is ver...|[the, design, is,...|\n|    1|Highly recommend ...|[highly, recommen...|\n|    0|I advise EVERYONE...|[i, advise, every...|\n|    1|    So Far So Good!.|[so, far, so, goo...|\n|    1|       Works great!.|    [works, great!.]|\n|    0|It clicks into pl...|[it, clicks, into...|\n+-----+--------------------+--------------------+\nonly showing top 20 rows\n\n+-----+--------------------+--------------------+--------------------+\n|label|              review|        review_words|            filtered|\n+-----+--------------------+--------------------+--------------------+\n|    0|So there is no wa...|[so, there, is, n...|[way, plug, us, u...|\n|    1|Good case, Excell...|[good, case,, exc...|[good, case,, exc...|\n|    1|Great for the jaw...|[great, for, the,...|   [great, jawbone.]|\n|    0|Tied to charger f...|[tied, to, charge...|[tied, charger, c...|\n|    1|   The mic is great.|[the, mic, is, gr...|       [mic, great.]|\n|    0|I have to jiggle ...|[i, have, to, jig...|[jiggle, plug, ge...|\n|    0|If you have sever...|[if, you, have, s...|[several, dozen, ...|\n|    1|If you are Razr o...|[if, you, are, ra...|[razr, owner...yo...|\n|    0|Needless to say, ...|[needless, to, sa...|[needless, say,, ...|\n|    0|What a waste of m...|[what, a, waste, ...|[waste, money, ti...|\n|    1|And the sound qua...|[and, the, sound,...|[sound, quality, ...|\n|    1|He was very impre...|[he, was, very, i...|[impressed, going...|\n|    0|If the two were s...|[if, the, two, we...|[two, seperated, ...|\n|    1|Very good quality...|[very, good, qual...|[good, quality, t...|\n|    0|The design is ver...|[the, design, is,...|[design, odd,, ea...|\n|    1|Highly recommend ...|[highly, recommen...|[highly, recommen...|\n|    0|I advise EVERYONE...|[i, advise, every...|[advise, everyone...|\n|    1|    So Far So Good!.|[so, far, so, goo...|       [far, good!.]|\n|    1|       Works great!.|    [works, great!.]|    [works, great!.]|\n|    0|It clicks into pl...|[it, clicks, into...|[clicks, place, w...|\n+-----+--------------------+--------------------+--------------------+\nonly showing top 20 rows\n\n+-----+--------------------+--------------------+--------------------+--------------------+\n|label|              review|        review_words|            filtered|                  TF|\n+-----+--------------------+--------------------+--------------------+--------------------+\n|    0|So there is no wa...|[so, there, is, n...|[way, plug, us, u...|(262144,[21872,61...|\n|    1|Good case, Excell...|[good, case,, exc...|[good, case,, exc...|(262144,[113432,1...|\n|    1|Great for the jaw...|[great, for, the,...|   [great, jawbone.]|(262144,[138356,2...|\n|    0|Tied to charger f...|[tied, to, charge...|[tied, charger, c...|(262144,[22836,35...|\n|    1|   The mic is great.|[the, mic, is, gr...|       [mic, great.]|(262144,[52197,80...|\n|    0|I have to jiggle ...|[i, have, to, jig...|[jiggle, plug, ge...|(262144,[99895,11...|\n|    0|If you have sever...|[if, you, have, s...|[several, dozen, ...|(262144,[8443,829...|\n|    1|If you are Razr o...|[if, you, are, ra...|[razr, owner...yo...|(262144,[80023,17...|\n|    0|Needless to say, ...|[needless, to, sa...|[needless, say,, ...|(262144,[15514,16...|\n|    0|What a waste of m...|[what, a, waste, ...|[waste, money, ti...|(262144,[154554,2...|\n|    1|And the sound qua...|[and, the, sound,...|[sound, quality, ...|(262144,[13381,52...|\n|    1|He was very impre...|[he, was, very, i...|[impressed, going...|(262144,[65435,93...|\n|    0|If the two were s...|[if, the, two, we...|[two, seperated, ...|(262144,[12304,13...|\n|    1|Very good quality...|[very, good, qual...|[good, quality, t...|(262144,[113432,1...|\n|    0|The design is ver...|[the, design, is,...|[design, odd,, ea...|(262144,[8287,989...|\n|    1|Highly recommend ...|[highly, recommen...|[highly, recommen...|(262144,[27545,31...|\n|    0|I advise EVERYONE...|[i, advise, every...|[advise, everyone...|(262144,[33799,37...|\n|    1|    So Far So Good!.|[so, far, so, goo...|       [far, good!.]|(262144,[28282,18...|\n|    1|       Works great!.|    [works, great!.]|    [works, great!.]|(262144,[12888,86...|\n|    0|It clicks into pl...|[it, clicks, into...|[clicks, place, w...|(262144,[27956,58...|\n+-----+--------------------+--------------------+--------------------+--------------------+\nonly showing top 20 rows\n\n<span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-20-5854f3e1465f&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">     19</span> wordsDF3<span class=\"ansiyellow\">.</span>show<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     20</span> <span class=\"ansired\">## HashingTF in SparkML cannot normalize term frequency with the total number of words in each document</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 21</span><span class=\"ansiyellow\"> </span><span class=\"ansigreen\">for</span> features_label <span class=\"ansigreen\">in</span> wordsDF3<span class=\"ansiyellow\">.</span>select<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;TF&quot;</span><span class=\"ansiyellow\">,</span> <span class=\"ansiblue\">&quot;score&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>take<span class=\"ansiyellow\">(</span><span class=\"ansicyan\">3</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     22</span>     <span class=\"ansigreen\">print</span><span class=\"ansiyellow\">(</span>features_label<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     23</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansicyan\">select</span><span class=\"ansiblue\">(self, *cols)</span>\n<span class=\"ansigreen\">    876</span>         <span class=\"ansiyellow\">[</span>Row<span class=\"ansiyellow\">(</span>name<span class=\"ansiyellow\">=</span><span class=\"ansiblue\">u&apos;Alice&apos;</span><span class=\"ansiyellow\">,</span> age<span class=\"ansiyellow\">=</span><span class=\"ansicyan\">12</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">,</span> Row<span class=\"ansiyellow\">(</span>name<span class=\"ansiyellow\">=</span><span class=\"ansiblue\">u&apos;Bob&apos;</span><span class=\"ansiyellow\">,</span> age<span class=\"ansiyellow\">=</span><span class=\"ansicyan\">15</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    877</span>         &quot;&quot;&quot;\n<span class=\"ansigreen\">--&gt; 878</span><span class=\"ansiyellow\">         </span>jdf <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>_jdf<span class=\"ansiyellow\">.</span>select<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">.</span>_jcols<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">*</span>cols<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    879</span>         <span class=\"ansigreen\">return</span> DataFrame<span class=\"ansiyellow\">(</span>jdf<span class=\"ansiyellow\">,</span> self<span class=\"ansiyellow\">.</span>sql_ctx<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    880</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py</span> in <span class=\"ansicyan\">__call__</span><span class=\"ansiblue\">(self, *args)</span>\n<span class=\"ansigreen\">   1131</span>         answer <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>gateway_client<span class=\"ansiyellow\">.</span>send_command<span class=\"ansiyellow\">(</span>command<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1132</span>         return_value = get_return_value(\n<span class=\"ansigreen\">-&gt; 1133</span><span class=\"ansiyellow\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansigreen\">   1134</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1135</span>         <span class=\"ansigreen\">for</span> temp_arg <span class=\"ansigreen\">in</span> temp_args<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansicyan\">deco</span><span class=\"ansiblue\">(*a, **kw)</span>\n<span class=\"ansigreen\">     67</span>                                              e.java_exception.getStackTrace()))\n<span class=\"ansigreen\">     68</span>             <span class=\"ansigreen\">if</span> s<span class=\"ansiyellow\">.</span>startswith<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;org.apache.spark.sql.AnalysisException: &apos;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 69</span><span class=\"ansiyellow\">                 </span><span class=\"ansigreen\">raise</span> AnalysisException<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">.</span>split<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;: &apos;</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">[</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">,</span> stackTrace<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     70</span>             <span class=\"ansigreen\">if</span> s<span class=\"ansiyellow\">.</span>startswith<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;org.apache.spark.sql.catalyst.analysis&apos;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     71</span>                 <span class=\"ansigreen\">raise</span> AnalysisException<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">.</span>split<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;: &apos;</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">[</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">,</span> stackTrace<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">AnalysisException</span>: u&quot;cannot resolve &apos;&#96;score&#96;&apos; given input columns: [review, review_words, label, TF, filtered];;\\n&apos;Project [TF#6765, &apos;score]\\n+- Project [label#6633, review#6634, review_words#6739, filtered#6749, UDF(filtered#6749) AS TF#6765]\\n   +- Project [label#6633, review#6634, review_words#6739, UDF(review_words#6739) AS filtered#6749]\\n      +- Project [label#6633, review#6634, UDF(review#6634) AS review_words#6739]\\n         +- LogicalRDD [label#6633, review#6634]\\n&quot;\n</div>","workflows":[],"startTime":1.481481547331E12,"submitTime":1.481481547319E12,"finishTime":1.481481548951E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"Convert Text Data into TF-IDF Words Vector","showCommandTitle":true,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"f31e55c3-2085-49c5-bf7e-ea0b3fa77ff2"},{"version":"CommandV1","origId":2850326087200627,"guid":"ad57ff15-2e23-4859-baf9-f9f16c255b4e","subtype":"command","commandType":"auto","position":3.0,"command":"from pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n\n# Split data into training and testing set \n(training, test) = amazon.randomSplit([0.7, 0.3])\n\n# Create a logistic regression instance\nlr = LogisticRegression(maxIter=10)\n\n# Use a pipeline to chain all transformers and estimators\npipeline = Pipeline(stages=[tokenizer, remover, hashingTF, idfModel, lr])\n\n# We now treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.\n# This will allow us to jointly choose parameters for all Pipeline stages.\n# A CrossValidator requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n# We use a ParamGridBuilder to construct a grid of parameters to search over.\nparamGrid = ParamGridBuilder() \\\n    .addGrid(hashingTF.numFeatures, [10, 50]) \\\n    .addGrid(lr.regParam, [0.1, 0.01]) \\\n    .build()\n\ncrossval = CrossValidator(estimator=pipeline,\n                          estimatorParamMaps=paramGrid,\n                          evaluator=BinaryClassificationEvaluator(),\n                          numFolds=3) \n\n# Run cross-validation, and choose the best set of parameters.\ncvModel = crossval.fit(training)\n\n# Make predictions on test documents. cvModel uses the best model found (lrModel).\nprediction = cvModel.transform(test)\nselected = prediction.select(\"review\", \"label\", \"probability\", \"prediction\").take(5)\nfor row in selected:\n    print(row)\n\n# Evaluate result with ROC\nevaluator = BinaryClassificationEvaluator(\n    labelCol=\"label\", metricName=\"areaUnderROC\")\nROC = evaluator.evaluate(prediction)\nROC","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Row(review=u&apos;A week later after I activated it, it suddenly died.&apos;, label=0, probability=DenseVector([0.5019, 0.4981]), prediction=0.0)\nRow(review=u&apos;AMAZON SUCKS.&apos;, label=0, probability=DenseVector([0.7487, 0.2513]), prediction=0.0)\nRow(review=u&apos;All I can do is whine on the Internet, so here it goes.The more I use the thing the less I like it.&apos;, label=0, probability=DenseVector([0.6887, 0.3113]), prediction=0.0)\nRow(review=u&quot;All in all, I&apos;d expected a better consumer experience from Motorola.&quot;, label=0, probability=DenseVector([0.5093, 0.4907]), prediction=0.0)\nRow(review=u&quot;As many people complained, I found this headset&apos;s microphone was very weak.&quot;, label=0, probability=DenseVector([0.8039, 0.1961]), prediction=0.0)\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"<span class=\"ansired\">AttributeError</span>: &apos;list&apos; object has no attribute &apos;collect&apos;","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">AttributeError</span>                            Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-39-48b054522107&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">     29</span> prediction <span class=\"ansiyellow\">=</span> cvModel<span class=\"ansiyellow\">.</span>transform<span class=\"ansiyellow\">(</span>test<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     30</span> selected <span class=\"ansiyellow\">=</span> prediction<span class=\"ansiyellow\">.</span>select<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;review&quot;</span><span class=\"ansiyellow\">,</span> <span class=\"ansiblue\">&quot;label&quot;</span><span class=\"ansiyellow\">,</span> <span class=\"ansiblue\">&quot;probability&quot;</span><span class=\"ansiyellow\">,</span> <span class=\"ansiblue\">&quot;prediction&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>take<span class=\"ansiyellow\">(</span><span class=\"ansicyan\">5</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 31</span><span class=\"ansiyellow\"> </span><span class=\"ansigreen\">for</span> row <span class=\"ansigreen\">in</span> selected<span class=\"ansiyellow\">.</span>collect<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     32</span>     <span class=\"ansigreen\">print</span><span class=\"ansiyellow\">(</span>row<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">AttributeError</span>: &apos;list&apos; object has no attribute &apos;collect&apos;\n</div>","workflows":[],"startTime":1.481481692215E12,"submitTime":1.481481692204E12,"finishTime":1.481481706906E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"Select Model Parameters with Cross Validation","showCommandTitle":true,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"82a09250-11c3-47c3-80a5-2021410fe84a"},{"version":"CommandV1","origId":2850326087200628,"guid":"332d6839-7360-4137-b7bc-7fde75018483","subtype":"command","commandType":"auto","position":4.0,"command":"","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">50</span><span class=\"ansired\">]: </span>0.6716321839080457\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"<span class=\"ansired\">IllegalArgumentException</span>: u&apos;BinaryClassificationEvaluator_4b36b1f1aaf45c0dff77 parameter metricName given invalid value accuracy.&apos;","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">IllegalArgumentException</span>                  Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-47-96885e25f197&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      1</span> evaluator = BinaryClassificationEvaluator(\n<span class=\"ansigreen\">      2</span>     labelCol=&quot;label&quot;, rawPredictionCol=&quot;prediction&quot;, metricName=&quot;accuracy&quot;)\n<span class=\"ansigreen\">----&gt; 3</span><span class=\"ansiyellow\"> </span>accuracy <span class=\"ansiyellow\">=</span> evaluator<span class=\"ansiyellow\">.</span>evaluate<span class=\"ansiyellow\">(</span>prediction<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      4</span> <span class=\"ansigreen\">print</span><span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;Test Error = %g&quot;</span> <span class=\"ansiyellow\">%</span> <span class=\"ansiyellow\">(</span><span class=\"ansicyan\">1.0</span> <span class=\"ansiyellow\">-</span> accuracy<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/ml/evaluation.py</span> in <span class=\"ansicyan\">evaluate</span><span class=\"ansiblue\">(self, dataset, params)</span>\n<span class=\"ansigreen\">     66</span>                 <span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>copy<span class=\"ansiyellow\">(</span>params<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>_evaluate<span class=\"ansiyellow\">(</span>dataset<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     67</span>             <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 68</span><span class=\"ansiyellow\">                 </span><span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>_evaluate<span class=\"ansiyellow\">(</span>dataset<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     69</span>         <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     70</span>             <span class=\"ansigreen\">raise</span> ValueError<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;Params must be a param map but got %s.&quot;</span> <span class=\"ansiyellow\">%</span> type<span class=\"ansiyellow\">(</span>params<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/ml/evaluation.py</span> in <span class=\"ansicyan\">_evaluate</span><span class=\"ansiblue\">(self, dataset)</span>\n<span class=\"ansigreen\">     95</span>         <span class=\"ansiyellow\">:</span><span class=\"ansigreen\">return</span><span class=\"ansiyellow\">:</span> evaluation metric<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     96</span>         &quot;&quot;&quot;\n<span class=\"ansigreen\">---&gt; 97</span><span class=\"ansiyellow\">         </span>self<span class=\"ansiyellow\">.</span>_transfer_params_to_java<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     98</span>         <span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>_java_obj<span class=\"ansiyellow\">.</span>evaluate<span class=\"ansiyellow\">(</span>dataset<span class=\"ansiyellow\">.</span>_jdf<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     99</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/ml/wrapper.py</span> in <span class=\"ansicyan\">_transfer_params_to_java</span><span class=\"ansiblue\">(self)</span>\n<span class=\"ansigreen\">     89</span>         <span class=\"ansigreen\">for</span> param <span class=\"ansigreen\">in</span> self<span class=\"ansiyellow\">.</span>params<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     90</span>             <span class=\"ansigreen\">if</span> param <span class=\"ansigreen\">in</span> paramMap<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 91</span><span class=\"ansiyellow\">                 </span>pair <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>_make_java_param_pair<span class=\"ansiyellow\">(</span>param<span class=\"ansiyellow\">,</span> paramMap<span class=\"ansiyellow\">[</span>param<span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     92</span>                 self<span class=\"ansiyellow\">.</span>_java_obj<span class=\"ansiyellow\">.</span>set<span class=\"ansiyellow\">(</span>pair<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     93</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/ml/wrapper.py</span> in <span class=\"ansicyan\">_make_java_param_pair</span><span class=\"ansiblue\">(self, param, value)</span>\n<span class=\"ansigreen\">     80</span>         java_param <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>_java_obj<span class=\"ansiyellow\">.</span>getParam<span class=\"ansiyellow\">(</span>param<span class=\"ansiyellow\">.</span>name<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     81</span>         java_value <span class=\"ansiyellow\">=</span> _py2java<span class=\"ansiyellow\">(</span>sc<span class=\"ansiyellow\">,</span> value<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 82</span><span class=\"ansiyellow\">         </span><span class=\"ansigreen\">return</span> java_param<span class=\"ansiyellow\">.</span>w<span class=\"ansiyellow\">(</span>java_value<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     83</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     84</span>     <span class=\"ansigreen\">def</span> _transfer_params_to_java<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py</span> in <span class=\"ansicyan\">__call__</span><span class=\"ansiblue\">(self, *args)</span>\n<span class=\"ansigreen\">   1131</span>         answer <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>gateway_client<span class=\"ansiyellow\">.</span>send_command<span class=\"ansiyellow\">(</span>command<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1132</span>         return_value = get_return_value(\n<span class=\"ansigreen\">-&gt; 1133</span><span class=\"ansiyellow\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansigreen\">   1134</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1135</span>         <span class=\"ansigreen\">for</span> temp_arg <span class=\"ansigreen\">in</span> temp_args<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansicyan\">deco</span><span class=\"ansiblue\">(*a, **kw)</span>\n<span class=\"ansigreen\">     77</span>                 <span class=\"ansigreen\">raise</span> QueryExecutionException<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">.</span>split<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;: &apos;</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">[</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">,</span> stackTrace<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     78</span>             <span class=\"ansigreen\">if</span> s<span class=\"ansiyellow\">.</span>startswith<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;java.lang.IllegalArgumentException: &apos;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 79</span><span class=\"ansiyellow\">                 </span><span class=\"ansigreen\">raise</span> IllegalArgumentException<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">.</span>split<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;: &apos;</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">[</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">,</span> stackTrace<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     80</span>             <span class=\"ansigreen\">raise</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     81</span>     <span class=\"ansigreen\">return</span> deco<span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">IllegalArgumentException</span>: u&apos;BinaryClassificationEvaluator_4b36b1f1aaf45c0dff77 parameter metricName given invalid value accuracy.&apos;\n</div>","workflows":[],"startTime":1.481484040991E12,"submitTime":1.48148404098E12,"finishTime":1.481484041607E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"6568a746-f4e8-4999-85f4-a5e408b3bb46"}],"dashboards":[],"guid":"0df5a2e0-2216-4c22-a4f8-ec960b88be2b","globalVars":{},"iPythonMetadata":null,"inputWidgets":{}};</script>
<script
 src="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/js/notebook-main.js"
 onerror="window.mainJsLoadError = true;"></script>
</head>
<body>
  <script>
if (window.mainJsLoadError) {
  var u = 'https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/js/notebook-main.js';
  var b = document.getElementsByTagName('body')[0];
  var c = document.createElement('div');
  c.innerHTML = ('<h1>Network Error</h1>' +
    '<p><b>Please check your network connection and try again.</b></p>' +
    '<p>Could not load a required resource: ' + u + '</p>');
  c.style.margin = '30px';
  c.style.padding = '20px 50px';
  c.style.backgroundColor = '#f5f5f5';
  c.style.borderRadius = '5px';
  b.appendChild(c);
}
</script>
</body>
</html>
