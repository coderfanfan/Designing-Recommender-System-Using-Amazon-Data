{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from IPython.display import display, Image\n",
    "import graphviz\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"covtype.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Cover_Type').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y'] = np.where((df['Cover_Type']==4) | (df['Cover_Type']==5), 1, 0)\n",
    "df.groupby('y').size()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# perform one-hot-encoding on categorical variables \n",
    "enc = OneHotEncoder(categories='auto',\n",
    "                    sparse='true',\n",
    "                    n_values = 'auto',\n",
    "                    handle_unknown='ignore')\n",
    "df = enc.fit_transform(df, y=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split features and targets \n",
    "X = df.drop(['Cover_Type','y'], axis=1)\n",
    "Y = df['y']\n",
    "\n",
    "#Spliting data into training, testing set \n",
    "np.random.seed(0)\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size = 0.95, stratify =Y, random_state=999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Defined Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(train_sizes, train_scores, valid_scores, \n",
    "                        score, title=\"Learning Curve\"):\n",
    "    # Create means and standard deviations of training set scores\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "\n",
    "    # Create means and standard deviations of test set scores\n",
    "    valid_mean = np.mean(valid_scores, axis=1)\n",
    "    valid_std = np.std(valid_scores, axis=1)\n",
    "\n",
    "    # Draw lines\n",
    "    plt.plot(train_sizes, train_mean, '--', color=\"#111111\",  label=\"Training score\")\n",
    "    plt.plot(train_sizes, valid_mean, color=\"#111111\", label=\"Cross-validation score\")\n",
    "\n",
    "    # Draw bands\n",
    "    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\n",
    "    plt.fill_between(train_sizes, valid_mean - valid_std, valid_mean + valid_std, color=\"#DDDDDD\")\n",
    "\n",
    "    # Create plot\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Training Set Size\"), plt.ylabel(score), plt.legend(loc=\"best\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_parameter_search_curve(params, train_mean, valid_mean, train_std, valid_std, \n",
    "                                       param_name, score, title='Hyper Parameter Tuning'):\n",
    "    # Draw lines\n",
    "    plt.plot(params, train_mean, '--', color=\"#111111\",  label=\"Training score\")\n",
    "    plt.plot(params, valid_mean, color=\"#111111\", label=\"Cross-validation score\")\n",
    "\n",
    "    # Draw bands\n",
    "    plt.fill_between(params, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\n",
    "    plt.fill_between(params, valid_mean - valid_std, valid_mean + valid_std, color=\"#DDDDDD\")\n",
    "\n",
    "    # Create plot\n",
    "    plt.title(title)\n",
    "    plt.xlabel(param_name), plt.ylabel(score), plt.legend(loc=\"best\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 No pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a classifier instance \n",
    "dt = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model, select model based on cross-validation performance\n",
    "scores_dt = cross_validate(dt, Xtrain, Ytrain, scoring= ['f1'],\n",
    "                           cv=5, return_train_score=True)\n",
    "\n",
    "print(\"Validate F1 macro: %0.2f (+/- %0.2f)\" % (scores_dt['test_f1'].mean(), scores_dt['test_f1'].std() * 2)) \n",
    "print(\"Train F1 macro: %0.2f (+/- %0.2f)\" % (scores_dt['train_f1'].mean(), scores_dt['train_f1'].std() * 2)) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# visualize tree without pruning\n",
    "dt = dt.fit(Xtrain, Ytrain)\n",
    "\n",
    "dot_data = tree.export_graphviz(dt, out_file='thisIsTheImagetree.dot', \n",
    "                                filled=True, rounded=True,  \n",
    "                                special_characters=True)  \n",
    " \n",
    "graph = pydotplus.graph_from_dot_file('thisIsTheImagetree.dot')  \n",
    "thisIsTheImage = Image(graph.create_png())\n",
    "display(thisIsTheImage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Pre-pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# available hyper parameters \n",
    "dt.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Max depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters searching space\n",
    "param_grid = [{'max_depth': range(1, 25)}]\n",
    "tuned_dt = GridSearchCV(dt, param_grid, cv=5,\n",
    "                        scoring= ['f1'], refit='f1', \n",
    "                        return_train_score=True)\n",
    "tuned_dt.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_dt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_single_parameter_search_curve(range(1, 25),\n",
    "                                   tuned_dt.cv_results_['mean_train_f1'], \n",
    "                                   tuned_dt.cv_results_['mean_test_f1'], \n",
    "                                   tuned_dt.cv_results_['std_train_f1'], \n",
    "                                   tuned_dt.cv_results_['std_test_f1'], \n",
    "                                   'max_depth', \n",
    "                                   'F1', \n",
    "                                   'Cover Type Hyper Parameter Tuning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters searching space\n",
    "param_grid = [{'min_samples_leaf': range(1, 100, 5)}]\n",
    "\n",
    "# Search parameters with cross-validation\n",
    "dt = DecisionTreeClassifier()\n",
    "tuned_dt = GridSearchCV(dt, param_grid, cv=5,\n",
    "                        scoring= ['f1'], refit='f1', \n",
    "                        return_train_score=True)\n",
    "tuned_dt.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_dt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot performance of different parameters\n",
    "plot_single_parameter_search_curve(range(1, 100, 5),\n",
    "                                   tuned_dt.cv_results_['mean_train_f1'], \n",
    "                                   tuned_dt.cv_results_['mean_test_f1'], \n",
    "                                   tuned_dt.cv_results_['std_train_f1'], \n",
    "                                   tuned_dt.cv_results_['std_test_f1'], \n",
    "                                   'min_samples_leaf', \n",
    "                                   'F1', \n",
    "                                   'Cover Type Hyper Parameter Tuning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3 min_impurity_decrease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters searching space\n",
    "param_grid = [{'min_impurity_decrease': np.linspace(0.0, 0.05, 20)}]\n",
    "\n",
    "# Search parameters with cross-validation\n",
    "dt = DecisionTreeClassifier()\n",
    "tuned_dt = GridSearchCV(dt, param_grid, cv=5,\n",
    "                        scoring= ['f1_macro'], refit='f1_macro', \n",
    "                        return_train_score=True)\n",
    "tuned_dt.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_dt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot performance of different parameters\n",
    "plot_single_parameter_search_curve(np.linspace(0.0, 0.05, 20),\n",
    "                                   tuned_dt.cv_results_['mean_train_f1_macro'], \n",
    "                                   tuned_dt.cv_results_['mean_test_f1_macro'], \n",
    "                                   tuned_dt.cv_results_['std_train_f1_macro'], \n",
    "                                   tuned_dt.cv_results_['std_test_f1_macro'], \n",
    "                                   'min_impurity_decrease', \n",
    "                                   'F1 macro', \n",
    "                                   'Hyper Parameter Tuning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.4 search across all hyper parameters for the best set "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Set the parameters searching space\n",
    "dt = DecisionTreeClassifier()\n",
    "param_grid = [{'min_samples_leaf': range(1, 16)}]\n",
    "tuned_dt = GridSearchCV(dt, param_grid, cv=5,\n",
    "                        scoring= ['f1_macro'], refit='f1_macro', \n",
    "                        return_train_score=True)\n",
    "tuned_dt.fit(Xtrain, Ytrain)\n",
    "\n",
    "print(tuned_dt.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-pruning"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://github.com/shenwanxiang/sklearn-post-prune-tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classifier of the best set of hyper parameters\n",
    "dt = DecisionTreeClassifier(max_depth = 20, min_samples_leaf=1, min_impurity_decrease=0.0)\n",
    "# learning curve\n",
    "train_sizes, train_scores, valid_scores = learning_curve(dt, Xtrain, Ytrain, scoring='f1', train_sizes=np.linspace(0.1, 1.0, 10), cv=5)\n",
    "plot_learning_curve(train_sizes, train_scores, valid_scores, \"F1\", title=\"Decision Tree Learning Curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. K-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Selection of K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a classifier instance\n",
    "neigh = KNeighborsClassifier()\n",
    "\n",
    "# Set the parameters searching space\n",
    "param_grid = [{'n_neighbors': range(1, 22, 3)}]\n",
    "\n",
    "# Search parameters with cross-validation\n",
    "tuned_neigh = GridSearchCV(neigh, param_grid, cv=5,\n",
    "                           scoring= ['f1'], refit='f1', \n",
    "                           return_train_score=True)\n",
    "tuned_neigh.fit(Xtrain, Ytrain)\n",
    "\n",
    "print(tuned_neigh.best_params_)\n",
    "\n",
    "# Plot performance of different parameters\n",
    "plot_single_parameter_search_curve(range(1, 22, 3),\n",
    "                                   tuned_neigh.cv_results_['mean_train_f1'], \n",
    "                                   tuned_neigh.cv_results_['mean_test_f1'], \n",
    "                                   tuned_neigh.cv_results_['std_train_f1'], \n",
    "                                   tuned_neigh.cv_results_['std_test_f1'], \n",
    "                                   'n_neighbors', \n",
    "                                   'F1', \n",
    "                                   'Hyper Parameter Tuning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a classifier instance\n",
    "neigh = KNeighborsClassifier()\n",
    "\n",
    "# Set the parameters searching space\n",
    "param_grid = [{'n_neighbors': range(1, 4)}]\n",
    "\n",
    "# Search parameters with cross-validation\n",
    "tuned_neigh = GridSearchCV(neigh, param_grid, cv=5,\n",
    "                           scoring= ['f1'], refit='f1', \n",
    "                           return_train_score=True)\n",
    "tuned_neigh.fit(Xtrain, Ytrain)\n",
    "\n",
    "print(tuned_neigh.best_params_)\n",
    "\n",
    "# Plot performance of different parameters\n",
    "plot_single_parameter_search_curve(range(1, 4),\n",
    "                                   tuned_neigh.cv_results_['mean_train_f1'], \n",
    "                                   tuned_neigh.cv_results_['mean_test_f1'], \n",
    "                                   tuned_neigh.cv_results_['std_train_f1'], \n",
    "                                   tuned_neigh.cv_results_['std_test_f1'], \n",
    "                                   'n_neighbors', \n",
    "                                   'F1', \n",
    "                                   'Hyper Parameter Tuning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classifier of the best set of hyper parameters\n",
    "neigh = KNeighborsClassifier(n_neighbors = 3)\n",
    "\n",
    "# learning curve\n",
    "train_sizes, train_scores, valid_scores = learning_curve(neigh, Xtrain, Ytrain, scoring='f1', train_sizes=np.linspace(0.1, 1.0, 10), cv=5)\n",
    "plot_learning_curve(train_sizes, train_scores, valid_scores, \"F1\", title=\"KNN Learning Curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a classifier instance\n",
    "grd = GradientBoostingClassifier()\n",
    "# available hyper parameters \n",
    "grd.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters searching space\n",
    "param_grid = [{'n_estimators': range(1, 201, 5)}]\n",
    "\n",
    "# Search parameters with cross-validation\n",
    "tuned_grd = GridSearchCV(grd, param_grid, cv=5,\n",
    "                           scoring= ['f1'], refit='f1', \n",
    "                           return_train_score=True)\n",
    "tuned_grd.fit(Xtrain, Ytrain)\n",
    "\n",
    "print(tuned_grd.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot performance of different parameters\n",
    "plot_single_parameter_search_curve(range(1, 201, 5),\n",
    "                                   tuned_grd.cv_results_['mean_train_f1'], \n",
    "                                   tuned_grd.cv_results_['mean_test_f1'], \n",
    "                                   tuned_grd.cv_results_['std_train_f1'], \n",
    "                                   tuned_grd.cv_results_['std_test_f1'], \n",
    "                                   'learning_rate', \n",
    "                                   'F1', \n",
    "                                   'Cover Type Hyper Parameter Tuning')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Set the parameters searching space\n",
    "param_grid = [{'learning_rate': np.linspace(0.1, 3.0, 2)}]\n",
    "\n",
    "# Search parameters with cross-validation\n",
    "tuned_grd = GridSearchCV(grd, param_grid, cv=5,\n",
    "                           scoring= ['f1_macro'], refit='f1_macro', \n",
    "                           return_train_score=True)\n",
    "tuned_grd.fit(Xtrain, Ytrain)\n",
    "\n",
    "print(tuned_grd.best_params_)\n",
    "\n",
    "# Plot performance of different parameters\n",
    "plot_single_parameter_search_curve(np.linspace(0.1, 3.0, 10),\n",
    "                                   tuned_grd.cv_results_['mean_train_f1_macro'], \n",
    "                                   tuned_grd.cv_results_['mean_test_f1_macro'], \n",
    "                                   tuned_grd.cv_results_['std_train_f1_macro'], \n",
    "                                   tuned_grd.cv_results_['std_test_f1_macro'], \n",
    "                                   'learning_rate', \n",
    "                                   'F1 macro', \n",
    "                                   'Hyper Parameter Tuning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set the parameters searching space\n",
    "param_grid = [{'max_depth': range(1, 20, 2)}]\n",
    "\n",
    "# Search parameters with cross-validation\n",
    "tuned_grd = GridSearchCV(grd, param_grid, cv=5,\n",
    "                           scoring= ['f1'], refit='f1', \n",
    "                           return_train_score=True)\n",
    "tuned_grd.fit(Xtrain, Ytrain)\n",
    "\n",
    "print(tuned_grd.best_params_)\n",
    "\n",
    "# Plot performance of different parameters\n",
    "plot_single_parameter_search_curve(range(1, 20, 2),\n",
    "                                   tuned_grd.cv_results_['mean_train_f1'], \n",
    "                                   tuned_grd.cv_results_['mean_test_f1'], \n",
    "                                   tuned_grd.cv_results_['std_train_f1'], \n",
    "                                   tuned_grd.cv_results_['std_test_f1'], \n",
    "                                   'max_depth', \n",
    "                                   'F1', \n",
    "                                   'Cover Type Hyper Parameter Tuning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot performance of different parameters\n",
    "plot_single_parameter_search_curve(range(1, 20, 2),\n",
    "                                   tuned_grd.cv_results_['mean_train_f1'], \n",
    "                                   tuned_grd.cv_results_['mean_test_f1'], \n",
    "                                   tuned_grd.cv_results_['std_train_f1'], \n",
    "                                   tuned_grd.cv_results_['std_test_f1'], \n",
    "                                   'max_depth', \n",
    "                                   'F1', \n",
    "                                   'Cover Type Hyper Parameter Tuning')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Set the parameters searching space\n",
    "grd = GradientBoostingClassifier(n_estimators = 20, learning_rate=0.1, \n",
    "      max_depth=5, min_samples_split=10, max_leaf_nodes = 30, min_impurity_decrease=0.01, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a classifier instance\n",
    "svm = SVC(random_state=0, degree=2)\n",
    "# available hyper parameters \n",
    "svm.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters searching space\n",
    "param_grid = [{'kernel': ['linear', 'poly']}]\n",
    "\n",
    "# Search parameters with cross-validation\n",
    "tuned_svm = GridSearchCV(svm, param_grid, cv=2,\n",
    "                         scoring= ['f1'], refit='f1', \n",
    "                         return_train_score=True, verbose=50)\n",
    "tuned_svm.fit(Xtrain, Ytrain)\n",
    "\n",
    "print(tuned_svm.best_params_)\n",
    "\n",
    "# Plot performance of different parameters\n",
    "plot_single_parameter_search_curve(['linear', 'poly'],\n",
    "                                   tuned_svm.cv_results_['mean_train_f1'], \n",
    "                                   tuned_svm.cv_results_['mean_test_f1'], \n",
    "                                   tuned_svm.cv_results_['std_train_f1'], \n",
    "                                   tuned_svm.cv_results_['std_test_f1'], \n",
    "                                   'kernel', \n",
    "                                   'F1', \n",
    "                                   'Hyper Parameter Tuning')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create a classifier instance\n",
    "clf = LinearSVC(random_state=0)\n",
    "\n",
    "# Set the parameters searching space\n",
    "param_grid = [{'max_iter': range(100, 1500, 200)}]\n",
    "\n",
    "# Search parameters with cross-validation\n",
    "tuned_neigh = GridSearchCV(neigh, param_grid, cv=3,\n",
    "                           scoring= ['f1_macro'], refit='f1_macro', \n",
    "                           return_train_score=True)\n",
    "tuned_neigh.fit(Xtrain, Ytrain)\n",
    "\n",
    "print(tuned_dt.best_params_)\n",
    "\n",
    "# Plot performance of different parameters\n",
    "plot_single_parameter_search_curve(range(1, 30, 3),\n",
    "                                   tuned_dt.cv_results_['mean_train_f1_macro'], \n",
    "                                   tuned_dt.cv_results_['mean_test_f1_macro'], \n",
    "                                   tuned_dt.cv_results_['std_train_f1_macro'], \n",
    "                                   tuned_dt.cv_results_['std_test_f1_macro'], \n",
    "                                   'n_estimators', \n",
    "                                   'F1 macro', \n",
    "                                   'Hyper Parameter Tuning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a classifier instance\n",
    "nn = MLPClassifier()\n",
    "                   \n",
    "# available hyper parameters \n",
    "nn.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set the parameters searching space\n",
    "#param_grid = [{'hidden_layer_sizes': [(3,), (6,), (9,), (12,), (3, 2), (6, 3), (9, 3), (12, 6)]}]\n",
    "#param_grid = [{'hidden_layer_sizes': [(20,), (40,), (60,), (20, 10), (40, 20)]}]\n",
    "#param_grid = [{'hidden_layer_sizes': [(100,), (150,), (100, 50), (60, 30)]}]\n",
    "param_grid = [{'hidden_layer_sizes': [(300,150)]}]\n",
    "# Search parameters with cross-validation\n",
    "tuned_nn = GridSearchCV(nn, param_grid, cv=5,\n",
    "                         scoring= ['f1'], refit='f1', \n",
    "                         return_train_score=True, verbose=50, n_jobs=-1)\n",
    "tuned_nn.fit(Xtrain, Ytrain)\n",
    "\n",
    "print(tuned_nn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_nn.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set the parameters searching space\n",
    "param_grid = [{'hidden_layer_sizes': [(200,100)],\n",
    "               'max_iter': range(10, 500, 50)\n",
    "              }]\n",
    "# Search parameters with cross-validation\n",
    "tuned_nn = GridSearchCV(nn, param_grid, cv=5,\n",
    "                         scoring= ['f1'], refit='f1', \n",
    "                         return_train_score=True, verbose=50, n_jobs=-1)\n",
    "tuned_nn.fit(Xtrain, Ytrain)\n",
    "\n",
    "print(tuned_nn.best_params_)\n",
    "# Plot performance of different parameters\n",
    "plot_single_parameter_search_curve(range(10, 500, 50),\n",
    "                                   tuned_nn.cv_results_['mean_train_f1'], \n",
    "                                   tuned_nn.cv_results_['mean_test_f1'], \n",
    "                                   tuned_nn.cv_results_['std_train_f1'], \n",
    "                                   tuned_nn.cv_results_['std_test_f1'], \n",
    "                                   'kernel', \n",
    "                                   'F1', \n",
    "                                   'Hyper Parameter Tuning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
